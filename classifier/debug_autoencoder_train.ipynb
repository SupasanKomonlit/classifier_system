{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library help operation\n",
    "from library.directory_handle import DirectoryHandle\n",
    "import library.image_handle as ImageHandle\n",
    "import library.data_handle  as DataHandle\n",
    "import library.command_handle as CommandHandle\n",
    "\n",
    "# Import library for plot image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import library for manage model part Core Layers\n",
    "from keras.layers import Input, Flatten, Dense, Reshape, Lambda\n",
    "# Import library for manage model part Convolution Layers\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "# Import library for mange model part activatin\n",
    "from keras.layers import Activation\n",
    "# Import Library for manage model part Model Object\n",
    "from keras.models import Model, Sequential\n",
    "# Import Library for manage model part optimizer\n",
    "from keras.optimizers import Adam\n",
    "# Import Library about model \n",
    "from keras.utils import plot_model\n",
    "# Import library for load model\n",
    "from keras.models import load_model\n",
    "# Import library operation in Keras tensor object\n",
    "#from keras import backend as K\n",
    "#K.clear_session()\n",
    "#Import library for normal process\n",
    "import numpy as np\n",
    "\n",
    "# ============================== MODEL CREATER FUNCTION ==========================================\n",
    "def model_encoder( input_dim, output_dim, \n",
    "        l_filters, l_kernels, l_strides, l_padding, \n",
    "        prefix = \"encoder_\" , activation = \"relu\"):\n",
    "    encoder_input = Input( shape = input_dim , name = prefix + \"input\" )\n",
    "    encoder = encoder_input\n",
    "    count = 0\n",
    "    for filters , kernels, strides, padding in zip( l_filters, l_kernels, l_strides, l_padding ):\n",
    "        count += 1\n",
    "        encoder = Conv2D( filters = filters,\n",
    "                kernel_size = kernels,\n",
    "                strides = strides,\n",
    "                padding = padding,\n",
    "                name = prefix + \"conv2d\" + str( count ) )( encoder )\n",
    "        encoder = Activation( activation ,\n",
    "                name = prefix + \"conv2d\" + str( count ) + \"_\" + activation )( encoder )\n",
    "    encoder = Flatten( name = prefix + \"flatten\" )(encoder)\n",
    "    encoder_output = Dense( output_dim,\n",
    "                name = prefix + \"output\" )( encoder )\n",
    "\n",
    "    encoder_model = Model( encoder_input , encoder_output )\n",
    "    encoder_model.name = prefix + \"model\"\n",
    "    shape_before_flatten = encoder_model.layers[ -3 ].output_shape[1:]\n",
    "\n",
    "    return encoder_input, encoder, encoder_output, encoder_model, shape_before_flatten\n",
    "\n",
    "def model_decoder( input_dim, shape_before_flatten, output_channel,\n",
    "        l_filters, l_kernels, l_strides, l_padding, \n",
    "        prefix = \"decoder_\" , activation = \"relu\"):\n",
    "    decoder_input = Input( shape = (input_dim,) , name = prefix + \"input\" )\n",
    "    decoder = Dense( np.prod( shape_before_flatten ),\n",
    "            name = prefix + \"input_post\")( decoder_input )\n",
    "    decoder = Reshape( shape_before_flatten,\n",
    "            name = prefix + \"input_reshape\" )( decoder )\n",
    "    count = 0\n",
    "    for filters , kernels, strides, padding in zip( l_filters, l_kernels, l_strides, l_padding ):\n",
    "        count += 1\n",
    "        decoder = Conv2DTranspose( filters = filters,\n",
    "                kernel_size = kernels,\n",
    "                strides = strides,\n",
    "                padding = padding,\n",
    "                name = prefix + \"conv2dt\" + str( count ) )( decoder )\n",
    "        decoder = Activation( activation ,\n",
    "                name = prefix + \"conv2dt\" + str( count ) + \"_\" + activation )( decoder )\n",
    "    decoder_output = Conv2DTranspose( filters = output_channel,\n",
    "            kernel_size = (3,3),\n",
    "            strides = 1,\n",
    "            padding = padding,\n",
    "            name = prefix + \"output\" )( decoder )\n",
    "    decoder_output = Activation( activation,\n",
    "                name = prefix + \"output_\" + activation )( decoder_output )\n",
    "\n",
    "    decoder_model = Model( decoder_input , decoder_output )\n",
    "    decoder_model.name = prefix + \"model\"\n",
    "\n",
    "    return decoder_input, decoder, decoder_output, decoder_model\n",
    "\n",
    "# ============================ MAIN FUNCTION TO RUN PROGRAM =====================================+\n",
    "# =====> PARAMETER\n",
    "_PATH_DATA = \"/home/zeabus/Documents/supasan/2019_deep_learning/PokemonData\"\n",
    "_CROP = True\n",
    "_COLOR = True\n",
    "_RATIO = 8\n",
    "_EPOCHES = 1\n",
    "_LATENT_SIZE = 64\n",
    "_MODEL_NAME = \"autoencoder3L64D\" # This will use to save model\n",
    "_LEARNING_RATE = 0.0005\n",
    "_SHOW_SIZE = False\n",
    "_VERBOSE = 1 # 0 is silence 1 is process bar and 2 is result\n",
    "# =====> Input Parameter\n",
    "print( \"Survey directory of data\")\n",
    "directory_handle = DirectoryHandle( _PATH_DATA )\n",
    "list_label , list_data = directory_handle.group_data()\n",
    "list_dictionary = directory_handle.group_dictionary()\n",
    "\n",
    "if _SHOW_SIZE : \n",
    "    width = []\n",
    "    height = []\n",
    "    for data in list_data:\n",
    "        width , height = ImageHandle.read_size( data , width, height )\n",
    "\n",
    "    CommandHandle.plot_scatter( width , height, \n",
    "            \"width (pixel)\" , \"height (pixel)\", \n",
    "            figname = \"picture_size\")\n",
    "\n",
    "square_size = ImageHandle.min_all_square_size1( list_data )\n",
    "square_size = square_size if square_size % 2 == 0 else square_size - 1\n",
    "print( f'This program parameter to input image is\\n\\tColor Image : {_COLOR}\\n\\tCrop Image :{_CROP}\\n\\tSquare size : {square_size}')\n",
    "\n",
    "input_dim = ( square_size , square_size , 3 if _COLOR else 1 )\n",
    "print( \"Part Setup Model\")\n",
    "encoder_input, encoder, encoder_output, encoder_model, shape_before_flatten = model_encoder(\n",
    "        input_dim = input_dim,\n",
    "        output_dim = _LATENT_SIZE,\n",
    "        l_filters = [ 64, 32, 16 ], \n",
    "        l_kernels = [ (3,3), (3,3), (3,3) ],\n",
    "        l_strides = [ 1, 2, 1 ], \n",
    "        l_padding = ['same', 'same', 'same'],\n",
    "        prefix = \"encoder_\",\n",
    "        activation = \"relu\")\n",
    "encoder_model.summary()\n",
    "\n",
    "decoder_input, decoder, decoder_output, decoder_model = model_decoder(\n",
    "        input_dim = _LATENT_SIZE,\n",
    "        shape_before_flatten = shape_before_flatten,\n",
    "        output_channel = input_dim[2],\n",
    "        l_filters = [ 16, 32, 64 ], \n",
    "        l_kernels = [ (3,3), (3,3), (3,3) ],\n",
    "        l_strides = [ 1, 2, 1 ], \n",
    "        l_padding = ['same', 'same', 'same'],\n",
    "        prefix = \"decoder_\",\n",
    "        activation = \"relu\" )\n",
    "decoder_model.summary()\n",
    "\n",
    "autoencoder_model = Model( encoder_input , decoder_model( encoder_output ) )\n",
    "autoencoder_model.name = _MODEL_NAME\n",
    "autoencoder_model.summary()\n",
    "\n",
    "print( \"\\nPart Prepare Data\\n\\tDownloading Data\" )\n",
    "X_data, Y_data = ImageHandle.prepare_label_data( list_label, list_data, square_size, \n",
    "        color = _COLOR , crop = _CROP )\n",
    "print( \"\\tSpliiting Data\")\n",
    "(X_train,Y_train) , (X_test,Y_test) = DataHandle.train_test_split( X_data , Y_data , _RATIO )\n",
    "\n",
    "# ========> Train autoencoder model\n",
    "print( \"\\nPart Training Model\")\n",
    "config = encoder_model.get_config()\n",
    "optimizer = Adam( lr = _LEARNING_RATE )\n",
    "autoencoder_model.compile( optimizer = optimizer,\n",
    "        loss = 'mean_squared_error',\n",
    "        metrics = ['accuracy'] )\n",
    "#input( \"Start train\")\n",
    "history = autoencoder_model.fit( [X_train],\n",
    "        [X_train],\n",
    "        validation_data = ( [X_test] , [X_test] ),\n",
    "        epochs = _EPOCHES,\n",
    "        verbose = _VERBOSE )\n",
    "#    print( autoencoder_model.train_on_batch( [X_train] , [X_train] ) )\n",
    "\n",
    "#input( \"Plot History\")\n",
    "fig_history_autoencoder = plt.figure( \"History Training Autoencoder Model \" + _MODEL_NAME )\n",
    "sub = fig_history_autoencoder.add_subplot( 2 , 1 , 1 )\n",
    "sub.plot( history.history['accuracy'] )\n",
    "sub.plot(history.history['val_accuracy'])\n",
    "sub.title('Model accuracy')\n",
    "sub.ylabel('Accuracy')\n",
    "sub.xlabel('Epoch')\n",
    "sub.legend(['Train', 'Test'], loc='upper left')\n",
    "sub = fig_history_autoencoder.add_subplot( 2 , 1 , 1 )\n",
    "sub.plot(history.history['loss'])\n",
    "sub.plot(history.history['val_loss'])\n",
    "sub.title('Model loss')\n",
    "sub.ylabel('Loss')\n",
    "sub.xlabel('Epoch')\n",
    "sub.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.draw()\n",
    "\n",
    "random_index = []\n",
    "for _ in range(0,10):\n",
    "    random_index.append( np.random.randint( len( X_test)))\n",
    "random_index = tuple( set( random_index ) )\n",
    "data = []\n",
    "for index in random_index :\n",
    "    data.append( X_test[ index ] )\n",
    "data = np.array( data )\n",
    "input( \"Plot Compare\")\n",
    "CommandHandle.plot_compare( data, autoencoder_model,\n",
    "    figname = \"Compare Result Atuencoder Model \" + autoencoder_model.name,\n",
    "    dest_type = np.float )\n",
    "\n",
    "autoencoder_model.save( autoencoder_model.name + \".h5\" )\n",
    "                          \n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
